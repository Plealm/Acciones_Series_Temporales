train_loss,epoch,step
6.18857479095459,0,49
5.600758075714111,1,99
5.398955821990967,2,149
5.432430267333984,3,199
5.440309047698975,4,249
5.189987659454346,5,299
5.244504451751709,6,349
5.361863613128662,7,399
4.941911697387695,8,449
5.041718006134033,9,499
4.669743537902832,10,549
4.718881130218506,11,599
5.005163669586182,12,649
4.780857086181641,13,699
4.698305130004883,14,749
4.958524703979492,15,799
4.807417869567871,16,849
4.815508842468262,17,899
4.821456432342529,18,949
4.767727375030518,19,999
4.371396541595459,20,1049
4.345132350921631,21,1099
4.56527042388916,22,1149
4.668217182159424,23,1199
4.714482307434082,24,1249
4.586731910705566,25,1299
4.740965843200684,26,1349
4.341598987579346,27,1399
4.184144496917725,28,1449
4.087122917175293,29,1499
4.205896854400635,30,1549
4.179519176483154,31,1599
4.298677921295166,32,1649
4.3036699295043945,33,1699
4.162206649780273,34,1749
4.512298107147217,35,1799
5.143254280090332,36,1849
4.184355735778809,37,1899
4.397631645202637,38,1949
4.326545238494873,39,1999
4.236131191253662,40,2049
4.248272895812988,41,2099
4.057368278503418,42,2149
3.847993850708008,43,2199
4.1033034324646,44,2249
3.9843673706054688,45,2299
3.9904251098632812,46,2349
4.144378185272217,47,2399
4.469503402709961,48,2449
4.3599324226379395,49,2499
